{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Optimizaci√≥n I. Tarea 3}$$\n",
    "$$\\textit{Y. Sarahi Garc√≠a Goz√°lez}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{lightblue}{Librer√≠as \\space }$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea realizada en MacOs. \n",
      "Las versiones de las librer√≠as y de python utilizadas fueron:\n",
      "\n",
      "Python version 3.11.7\n",
      "Numpy version 1.26.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Tarea realizada en MacOs. \\nLas versiones de las librer√≠as y de python utilizadas fueron:\\n\")\n",
    "from platform import python_version\n",
    "print(\"Python version\", python_version())\n",
    "print(\"Numpy version\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon de la m√°quina: 2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "#imprimimos el epsilon de la m√°quina\n",
    "epsilon = np.finfo(float).eps\n",
    "print(\"Epsilon de la m√°quina:\", epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{lightblue}{Ejercicio \\space 1}$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Programar la funci√≥n que implementa el algoritmo de backtracking \n",
    "   (Algoritmo 2 de la Clase 6) que usa la condici√≥n de descenso suficiente\n",
    "   (condici√≥n de Armijo) para seleccionar el tama√±o de paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking(alpha_ini,rho,c,x_k,f,f_k,df_k,p_k,iter_max):\n",
    "\n",
    "    '''\n",
    "        Esta funcion parte de un tama√±o de paso inicial alpha_ini y lo va recortando hasta que\n",
    "        cumple la cond de descenso suficiente\n",
    "\n",
    "        parametros:\n",
    "            valores (float): alpha_ini, rho entre (0,1), f(x_k), Df(x_k) (gradiente en el punto x_k), c_1, \n",
    "            direccion de descenso (np.rray): p_k \n",
    "\n",
    "        returns:\n",
    "            el tama√±o de paso a_k\n",
    "            numero de iteraciones realizadas i_k\n",
    "    '''\n",
    "\n",
    "    alpha=alpha_ini #fijamos alpha como el alpha inicial\n",
    "    gp=c*np.dot(df_k,p_k) #hacemos el producto gradiente por direccion de descenso p\n",
    "    \n",
    "    for i in range(iter_max):\n",
    "        x_kp=x_k+alpha*p_k\n",
    "\n",
    "        #si la condicion de descenso se cumple, terminamos\n",
    "        if f(x_kp)<=(f_k + alpha*gp):\n",
    "            return alpha,i,True\n",
    "\n",
    "        alpha=alpha*rho #si no se cumple la cond, hacemos alpha*rho\n",
    "        print(alpha)\n",
    "\n",
    "        \n",
    "    return  alpha,i,False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Programar la funci√≥n que implementa el algoritmo de descenso m√°ximo con\n",
    "   backtracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La funci√≥n $f(\\mathbf{x})$, \n",
    "- el gradiente $\\nabla f(\\mathbf{x})$ de la funci√≥n $f$, \n",
    "- un punto inicial $\\mathbf{x}_{0}$, \n",
    "- las tolerancia $\\tau>0$, \n",
    "- el n√∫mero m√°ximo de iteraciones $N$ para el algoritmo de descenso m√°ximo, \n",
    "- el valor inicial $\\alpha_{ini}$,\n",
    "- el valor $\\rho \\in (0,1)$,\n",
    "- la constante $c_1 \\in (0,1)$ para la condici√≥n de Armijo y\n",
    "- el n√∫mero m√°ximo de iteraciones $N_{gs}$ para el m√©todo de la secci√≥n dorada.\n",
    "\n",
    "La funci√≥n devuelve \n",
    "- El √∫ltimo punto $\\mathbf{x}_{k}$ generado por el algoritmo,\n",
    "- el n√∫mero $k$ de iteraciones realizadas y\n",
    "- Una variable indicadora que es $True$ si el algoritmo termina por \n",
    "  cumplirse la condici√≥n de paro ($\\|\\alpha_k \\mathbf{p}_{k}\\| < \\tau$) o\n",
    "  $False$ si termina porque se alcanz√≥ el n√∫mero m√°ximo de iteraciones.\n",
    "- Si $n\\ne 2$, devuelve un arreglo vaci√≥. En caso contrario, devuelve un \n",
    "  arreglo que contiene las componentes de los puntos de la secuencia, el\n",
    "  tama√±o de paso y la cantidad de iteraciones que hizo el algoritmo \n",
    "  de backtracking en cada iteraci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def descenso_maximo_backtracking(f,df,x0,alpha_ini,rho,c,tau,max_iter,max_iter_b):\n",
    "    '''\n",
    "    Esta funcion busca el minimo de la funcion f usando la tecnica de backtracking\n",
    "\n",
    "    Parametros: \n",
    "        f: funci√≥n a optimizar\n",
    "        df: gradiente de f\n",
    "        x_0: valor inicial\n",
    "        tau,N: tolerancia y numero maximo de iteraciones (descenso)\n",
    "        parametros de \n",
    "\n",
    "        NOTA:los argumentos predeterminados son espec√≠ficos para este ejercicio y n=2\n",
    "    \n",
    "    returns:\n",
    "        x_k: ultimo punto de la sucesi√≥n que genera el algoritmo\n",
    "        k: n√∫mero de iteraciones\n",
    "        True/False: Indica si se satisfizo la condici√≥n de tolerancia\n",
    "        x1,x2...xk: sucesi√≥n de puntos (np.array)\n",
    "        \n",
    "    '''\n",
    "    n=len(x0)\n",
    "    x_k=x0\n",
    "    indicador=False\n",
    "    f_k=f(x_k)\n",
    "    df_k=df(x_k)\n",
    "\n",
    "\n",
    "    if n==2:\n",
    "        m = np.zeros((max_iter+1,4))\n",
    "        m[0,:] = x0[0],x0[1],1,0\n",
    "    \n",
    " \n",
    "    for k in range(max_iter):\n",
    "        #calculmos pk y ak\n",
    "        p_k=-df_k\n",
    "        a_k,i,ind=backtracking(alpha_ini,rho,c,x_k,f,f_k,df_k,p_k,max_iter_b)\n",
    "   \n",
    "        if not ind:\n",
    "            print('Insuficientes iteraciones Backtracking', a_k)\n",
    "\n",
    "        x_k=x_k+(a_k*p_k)\n",
    "        \n",
    "        if n==2:\n",
    "            m[k,:]= x_k[0],x_k[1],a_k,i\n",
    "\n",
    "\n",
    "        if norm(a_k*p_k)<tau:#si se cumple la condicion de tolerania:\n",
    "            indicador=True #indicador verdadero\n",
    "            break #y romepos el ciclo\n",
    "\n",
    "        f_k=f(x_k)\n",
    "        df_k=df(x_k)\n",
    "\n",
    "        \n",
    "    if n==2:\n",
    "        return x_k,k,indicador,m\n",
    "    \n",
    "    return x_k,k,indicador,None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Para probar el algoritmo, programe las siguientes funciones, calcule su gradiente \n",
    "   de manera anal√≠tica y programe la funci√≥n correspondiente. Use cada punto \n",
    "   $\\mathbf{x}_0$ como punto inicial del algoritmo.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = sqrt(epsilon) #tolerancia (despu√©s multiplicaremos por sqrt(n))\n",
    "aini = 1.0 \n",
    "rho  = 0.8 \n",
    "c1   = 0.1\n",
    "N    = 30000 #iter maximas para descenso\n",
    "Nb   = 600 #iter maximas para backtracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funci√≥n de Himmelblau:** Para $\\mathbf{x}=(x_1,x_2)$\n",
    "\n",
    "$$ f(\\mathbf{x}) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2. $$\n",
    "$$ \\mathbf{x}_0 = (2.,4.) $$\n",
    "$$ \\mathbf{x}_0 = (0.,0.) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n objetivo\n",
    "def Himmelblau(x):\n",
    "    return (x[0]**2 + x[1] - 11)**2 + (x[0] + x[1]**2 - 7)**2;\n",
    "\n",
    "# Gradiente de la funci√≥n objetivo\n",
    "def D_Himmelblau(x):\n",
    "    gx = 4*x[0]*(x[0]**2 + x[1] - 11) + 2*(x[0] + x[1]**2 - 7)\n",
    "    gy = 2*(x[0]**2 + x[1] - 11) + 4*x[1]*(x[0] + x[1]**2 - 7)\n",
    "    return np.array([gx, gy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cada caso imprima los resultados:\n",
    "- El n√∫mero de iteraciones realizadas $k$\n",
    "- El punto $\\mathbf{x}_k$ obtenido\n",
    "- $f(\\mathbf{x}_k)$\n",
    "- $\\|\\nabla f(\\mathbf{x}_k)\\|$\n",
    "- La variable que indica si el algoritmo termin√≥ porque se cumpli√≥ el criterio de paro o no.\n",
    "Adem√°s, si $n=2$, imprima\n",
    "- El valor promedio de los tama√±os de paso $\\alpha_0, \\alpha_1, ..., \\alpha_k$.\n",
    "- El valor promedio de las iteraciones $i_0, i_1, ..., i_k$ realizadas por el algoritmo de backtracking.\n",
    "- La gr√°fica de los contornos de nivel de la funci√≥n y la trayectoria\n",
    "  de los puntos $\\mathbf{x}_0, \\mathbf{x}_1, ..., \\mathbf{x}_k$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num.Iter =  29\n",
      "xk       =  [3. 2.]\n"
     ]
    }
   ],
   "source": [
    "x0  = np.array([2,4])\n",
    "n   = len(x0)\n",
    "tau = np.sqrt(n) * tau\n",
    "\n",
    "xk, k, indicador, m = descenso_maximo_backtracking(Himmelblau,D_Himmelblau,x0,aini,rho,c1,tau,N,Nb)\n",
    "\n",
    "print('Num.Iter = ', k)\n",
    "print('xk       = ', xk)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00000000e+00, 4.00000000e+00, 6.03833988e-19, 1.88000000e+02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funci√≥n de Beale :** Para $\\mathbf{x}=(x_1,x_2)$\n",
    "\n",
    "$$ f(\\mathbf{x}) = (1.5-x_1 + x_1x_2)^2 + (2.25 - x_1 + x_1x_2^2)^2 + (2.625 - x_1 + x_1x_2^3)^2.$$\n",
    "$$ \\mathbf{x}_0 = (2.,3.) $$\n",
    "$$ \\mathbf{x}_0 = (2.,4.) $$\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la funci√≥n f\n",
    "def Beale(x):\n",
    "    return (1.5 - (x[0]) + (x[0])*(x[1]))**2 + (2.25 - (x[0]) + (x[0])*(x[1])**2)**2 + (2.625 - (x[0]) + (x[0])*(x[1])**3)**2\n",
    "\n",
    "def D_Beale(x):\n",
    "    Partial_Beale_dx1 = 2*(1.5 - (x[0]) + (x[0])*(x[1]))*(-1 + (x[1])) + 2*(2.25 - (x[0]) + (x[0])*(x[1])**2)*(-1 + (x[1])**2) + 2*(2.625 - (x[0]) + (x[0])*(x[1])**3)*(-1 + (x[1])**3)\n",
    "    Partial_Beale_dx2 = 2*(1.5 - (x[0]) + (x[0])*(x[1]))*((x[0])) + 2*(2.25 - (x[0]) + (x[0])*(x[1])**2)*(2*(x[0])*(x[1])) + 2*(2.625 - (x[0]) + (x[0])*(x[1])**3)*(3*(x[0])*(x[1])**2)\n",
    "    return np.array([Partial_Beale_dx1, Partial_Beale_dx2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funci√≥n de Rosenbrock:** Para $\\mathbf{x}=(x_1,x_2, ..., x_n)$\n",
    "\n",
    "$$ f(\\mathbf{x}) = \\sum_{i=1}^{n-1} \\left[100(x_{i+1} - x_i^2)^2 + (1-x_i)^2 \\right]\n",
    "\\quad n\\geq 2.$$\n",
    "$$ \\mathbf{x}_0 = (-2.1, 4.5) $$\n",
    "$$ \\mathbf{x}_0 = (-1.2, 1.0) $$\n",
    "$$ \\mathbf{x}_0 = (-2.1, 4.5, -2.1, 4.5, -2.1, 4.5, -2.1, 4.5, -2.1, 4.5) $$\n",
    "$$ \\mathbf{x}_0 = (-1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0, -1.2, 1.0) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rosenbrock(x):\n",
    "    n = len(x)\n",
    "    suma = 0\n",
    "    for i in range(n-1):\n",
    "        suma += 100 * (x[i+1] - x[i]**2)**2 + (1 - x[i])**2\n",
    "    return suma\n",
    "\n",
    "def D_Rosenbrock(x):\n",
    "    n = len(x)\n",
    "    gradient = np.zeros(n)\n",
    "    for i in range(n-1):\n",
    "        gradient[i] += -400 * x[i] * (x[i+1] - x[i]**2) - 2 * (1 - x[i])\n",
    "        gradient[i+1] += 200 * (x[i+1] - x[i]**2)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Nocedal sugiere que la constante $c_1$ sea del orden de $0.0001$. \n",
    "   Use $c_1=0.0001$ y  repeta la prueba con la funci√≥n de Beale y \n",
    "   explique en qu√© casos conviene usar un valor grande o peque√±o de $c_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{lightblue}{Ejercicio \\space 2}$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{lightblue}{Ejercicio \\space 3}$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Verificamos si $p_0$ es direcci√≥n de descenso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El gradiente de f:\n",
    "\\begin{align*}\n",
    "f(x_1, x_2) &= 5 + (x_1)^2 + (x_2)^2 \\\\\n",
    "\\nabla f(x_1, x_2) &= \\nabla f{x_1}{x_2} \\\\\n",
    "&= (2x_1, 2x_2)\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\implies \\nabla f(\\textbf{x}_0)= (-2, 2)\n",
    "\\end{align*}\n",
    "\n",
    "* Direcci√≥n p:\n",
    "\n",
    "\\begin{align*}\n",
    "\\textbf{p}_0=(1,0) \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "&\\implies \\nabla f(\\textbf{x}_0)\\textbf{p}_0=(-2,2)^T (1,0)=-2+0=-2\\\\\n",
    "\\end{align*}\n",
    "\n",
    "$$\\implies \\nabla f(\\textbf{x}_0)\\textbf{p}_0 <0$$\n",
    "\n",
    "Por lo que $p_0$ es direcci√≥n de descenso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Encontramos $\\alpha_{max}$ que satisface la direcci√≥n de descenso:\n",
    "\n",
    "\n",
    "* f evaluada en $x_0 + p_0$ \n",
    "$$f(x_0 + p_0)=f((-1,1)+(1,0))=f(0,1)=6$$\n",
    "\n",
    "* f evaluada en $x_0$\n",
    "\n",
    "$$f(x_0)=f(-1,1)=7$$\n",
    "\n",
    "*Establecemos la desigualdad de la condici√≥n de descenso suficiente:\n",
    "\n",
    "$$f(x_0 + p_0) \\leq f(x_0) + c_1\\alpha \\textbf{p}_0^T \\nabla f(x_0) $$\n",
    "\n",
    "$$6 \\leq 7+ 10^{-4} \\alpha (-2)$$\n",
    "\n",
    "*despejamos $\\alpha$\n",
    "\n",
    "$$\\alpha \\leq 20^{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{lightblue}{Ejercicio \\space 4}$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $f ‚à∂ Rn ‚Üí R$ y S una matriz no singular de tama√±o $n \\times n$. Si $x = Sy$ para $y \\in Rn$ y definimos\n",
    "$g(y) = f(Sy)$.\n",
    "\n",
    "* A plicando la regla de la cadena muestre que $\\nabla g(y) = S^{‚ä§} \\nabla f(x)$\n",
    "\n",
    "\n",
    "Partimos del gradiente de $g(y)$:\n",
    "$$\\nabla _y g(y)= \\nabla _y f(Sy)=\\nabla _y f(x)$$\n",
    "\n",
    "$$\\implies \\nabla _y g(y)= \\nabla _x f(x) * \\nabla _y x$$\n",
    "\n",
    "$$\\implies \\nabla _y g(y)= \\nabla _x f(x) * \\nabla _y Sy $$\n",
    "\n",
    "S es una matriz y $ \\nabla _y y=(1,1,1,1...)$, por lo que \n",
    "\n",
    "$$\\nabla _y g(y)= S^{‚ä§}  \\nabla _x f(x)   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Muestre que $‚àíD\\nablaùëì(x_k)$ con $D=SS^{‚ä§}$ es una direcci√≥n de descenso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos del producto entre e√± grandiente y  $ -D\\nabla f(x)$\n",
    "\n",
    "\n",
    "\n",
    "$$\\nabla f(x)^{‚ä§} [-D\\nabla f(x)]=-\\nabla f(x)^{‚ä§}  SS^{‚ä§}  \\nabla f(x)$$\n",
    "\n",
    "$$\\implies -[\\nabla f(x)^{‚ä§}  S][S^{‚ä§}  \\nabla f(x) ]$$\n",
    "\n",
    "$$\\implies -[\\nabla f(x)  S^{‚ä§}]^{‚ä§}[S^{‚ä§}  \\nabla f(x) ]$$\n",
    "\n",
    "\n",
    "Pero usando que $\\nabla _y g(y)= S^{‚ä§}  \\nabla _x f(x) $ (resultado anterior)\n",
    "\n",
    "\n",
    "$$\\implies \\nabla f(x)^{‚ä§} [-D\\nabla f(x)]=-[\\nabla _y g(y)]^{‚ä§}[\\nabla _y g(y)]=-||\\nabla _y g(y)||^2$$\n",
    "\n",
    "Y la norma siempre es mayor o igual que cero, por lo que \n",
    "\n",
    "$$\\nabla f(x)^{‚ä§} [-D\\nabla f(x)] \\leq 0$$\n",
    "\n",
    "As√≠ que $-D\\nabla f(x)$ es una direcci√≥n de descenso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
