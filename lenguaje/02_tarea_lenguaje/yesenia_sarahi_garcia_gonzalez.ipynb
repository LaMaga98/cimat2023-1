{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{PLN. Tarea 2: Minería de texto básica}$$\n",
    "$$\\textit{Y. Sarahi García Gozález}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import Counter\n",
    "import matplotlib.pylab as plt\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "#clasificacion\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,precision_recall_fscore_support,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea realizada en MacOs. \n",
      "Las versiones de las librerías y de python utilizadas fueron:\n",
      "\n",
      "Python version 3.11.5\n",
      "Numpy version 1.23.5\n",
      "NLTK version 3.8.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Tarea realizada en MacOs. \\nLas versiones de las librerías y de python utilizadas fueron:\\n\")\n",
    "from platform import python_version\n",
    "print(\"Python version\", python_version())\n",
    "print(\"Numpy version\", np.__version__)\n",
    "print(\"NLTK version\", nltk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4.5 color='lightblue'>\n",
    "\n",
    "$\\textit{Ejercicio 2. Bolsas de Palabras, Bigramas y Emociones}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Preparación de texto, corpus y diccionarios}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_text_from_file(path_corpus,path_truth):\n",
    "\n",
    "    tr_txt=[]\n",
    "    tr_labels=[]\n",
    "\n",
    "    with open(path_corpus, \"r\") as f_corpus,open(path_truth, \"r\") as f_truth:\n",
    "        for tweet in f_corpus:\n",
    "            tr_txt += [tweet]\n",
    "        for label in f_truth:\n",
    "            tr_labels += [label]   \n",
    "             \n",
    "    return tr_txt, tr_labels\n",
    "\n",
    "\n",
    "def create_corpus_from_text(text,tokenizer):\n",
    "    corpus_palabras=[]\n",
    "    for documento in text:\n",
    "        corpus_palabras+=tokenizer.tokenize(documento)\n",
    "\n",
    "    return corpus_palabras\n",
    "\n",
    "\n",
    "def create_dic_freq(corpus,n):\n",
    "    fdist = nltk.FreqDist(corpus)\n",
    "    aux=[(fdist[key],key) for key in fdist]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    aux=aux[:n]\n",
    "\n",
    "    return aux\n",
    "\n",
    "def create_dic_ranking(dic_freq):\n",
    "    dict_indices=dict()\n",
    "    cont = 0\n",
    "    for weight, word in dic_freq:\n",
    "        dict_indices[word]= cont\n",
    "        cont+= 1\n",
    "\n",
    "    return dict_indices\n",
    "\n",
    "#Clasificador\n",
    "\n",
    "parameters={'C':[0.05,0.12,0.25,0.5,1,2,4]} #parámetro de complejidad\n",
    "\n",
    "#llamamos el clasificador SVM\n",
    "#nota: cambié el max_iter y dual porque me aparecían una serie de warnings pero no cambiaron los resultados\n",
    "svr=svm.LinearSVC(class_weight='balanced',dual='auto',max_iter=3000) \n",
    "\n",
    "#grid search recide el objeto de clasificacion\n",
    "grid=GridSearchCV(estimator=svr,param_grid=parameters,n_jobs=8,scoring=\"f1_macro\",cv=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardamos los textos de entrenamiento y validación\n",
    "tr_txt,tr_labels=get_text_from_file(\"/Users/ely/Documents/Maestria/segundo_semestre/cimat2023-1/lenguaje/practicas/03_practica/mex20_train.txt\",\"/Users/ely/Documents/Maestria/segundo_semestre/cimat2023-1/lenguaje/practicas/03_practica/mex20_train_labels.txt\")\n",
    "val_txt,val_labels=get_text_from_file(\"/Users/ely/Documents/Maestria/segundo_semestre/cimat2023-1/lenguaje/practicas/03_practica/mex20_val.txt\",\"/Users/ely/Documents/Maestria/segundo_semestre/cimat2023-1/lenguaje/practicas/03_practica/mex20_val_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connvertimos a lista las etiquetas\n",
    "tr_labels=list(map(int,tr_labels))\n",
    "val_labels=list(map(int,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizamos\n",
    "tokenizer=TweetTokenizer()\n",
    "#Generamos el corpus\n",
    "corpus_palabras=create_corpus_from_text(tr_txt,tokenizer)\n",
    "#Generamos diccionario de frecuencias con las primeras 5 mil palabras\n",
    "dict_freq=create_dic_freq(corpus_palabras,5000)\n",
    "#Generamos diccionario de indices\n",
    "dict_indices=create_dic_ranking(dict_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me - 10\n",
      "el - 11\n",
      "en - 12\n",
      "se - 13\n",
      "es - 14\n",
      "con - 15\n",
      "? - 16\n",
      "verga - 17\n",
      "los - 18\n",
      "madre - 19\n",
      "por - 20\n",
      "las - 21\n",
      "\" - 22\n",
      "un - 23\n",
      "te - 24\n",
      "mi - 25\n",
      "lo - 26\n",
      "putas - 27\n",
      "una - 28\n",
      "... - 29\n"
     ]
    }
   ],
   "source": [
    "#imprimimos algunos elementos del diccionario de indices\n",
    "lista_indices = list(dict_indices.items())\n",
    "for clave, valor in lista_indices[10:30]:\n",
    "    print(clave, \"-\", valor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3.5 color='lightblue'>\n",
    "\n",
    "1,2,3. Evalue BoW con pesado binario, de frecuencia y tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Bolsas de palabras con distintos equemas de pesado y sin normalizar}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#________________________________PESADO_BINARIO________________________________#\n",
    "\n",
    "\n",
    "#matriz_nxm de bolsa de palabras n=numero de textos, m=numero de palabras (5000)\n",
    "def build_binary_bow(tr_txt,dic_freq,dic_indices):\n",
    "    '''\n",
    "    Función que genera la bolsa de palabras con pesado binario\n",
    "\n",
    "    '''\n",
    "    BoW=np.zeros((len(tr_txt),len(dic_freq)),dtype=int) #construimos bolsta de palabras en ceros\n",
    "    cont_documento=0 #indice que recorre las FILAS\n",
    "\n",
    "    for tr in tr_txt:#recorremos cada documento\n",
    "        fdist_doc=nltk.FreqDist(tokenizer.tokenize(tr))#hacemos freqDist (tokenizado con el tokenizador ya definido) de cada documento\n",
    "        for word in fdist_doc: #para cada palabra en el diccionario del documento\n",
    "            if word in dic_indices: #si la palabra está en el corte final\n",
    "                #AGREGAMOS un uno en el lugar correspondiente\n",
    "                BoW[cont_documento,dic_indices[word]] = 1 \n",
    "\n",
    "        cont_documento+=1\n",
    "\n",
    "    return BoW\n",
    "\n",
    "#________________________________PESADO_FRECUENCIA________________________________#\n",
    "\n",
    "#matriz_nxm de bolsa de palabras n=numero de textos, m=numero de palabras (5000)\n",
    "def build_freq_bow(tr_txt,dic_feq,dic_inices):\n",
    "    BoW=np.zeros((len(tr_txt),len(dic_feq)),dtype=int) #construimos bolsta de palabras en ceros\n",
    "    cont_documento=0 #indice que recorre las FILAS\n",
    " \n",
    "    for tr in tr_txt:#recorremos cada documento\n",
    "        fdist_doc=nltk.FreqDist(tokenizer.tokenize(tr))#hacemos freqDist (tokenizado con el tokenizador ya definido) de cada documento\n",
    "        for word in fdist_doc: #para cada palabra en el diccionario del documento\n",
    "            if word in dic_inices: #si la palabra está en el corte final\n",
    "                #le asignamos su frecuencia\n",
    "                BoW[cont_documento,dic_inices[word]] = fdist_doc[word]\n",
    "\n",
    "        cont_documento+=1\n",
    "\n",
    "    return BoW\n",
    "\n",
    "#________________________________PESADO_TFIDF________________________________#\n",
    "\n",
    "#primero calculamos el num de documentos en que aparece cada palabra\n",
    "def df(tr_txt, dic_indices):\n",
    "    df = np.zeros(5000, dtype=int)\n",
    "\n",
    "    # comp list para las frecuencias de cada documento\n",
    "    fdist_docs = [nltk.FreqDist(tokenizer.tokenize(tr)) for tr in tr_txt]\n",
    "\n",
    "    #iteramos sobre cada palbra\n",
    "    for word in dic_indices:\n",
    "        #obtenemos el indice de la palabra\n",
    "        index = dic_indices[word] \n",
    "        for fdist_doc in enumerate(fdist_docs): #iteramos osbre cada documento\n",
    "            if word in fdist_doc: #si la palabra está en el documento actual\n",
    "                df[index] += 1 #agredamos uno al conador de esa palabra\n",
    "\n",
    "    return df\n",
    "\n",
    "#\n",
    "def build_tfidf_bow(tr_txt, dic_freq, dic_indices):\n",
    "    BoW = build_freq_bow(tr_txt, dic_freq, dic_indices) #la bolsa de palabras de frecuencias es el tf\n",
    "    df_list = df(tr_txt, dic_indices) #llamamos a la duncion df\n",
    "    N = len(tr_txt)\n",
    "    for i in range(N):\n",
    "        for j, df_val in enumerate(df_list): \n",
    "            if df_val!=0: #si df es distinto de ceo (puede ser cero para el conjunto de validacion, por ejemplo que contiene menos lementos )\n",
    "                BoW[i][j] *= np.log(N / df_val) #tfxdf\n",
    "\n",
    "    return BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos las bolsas de palabrascon pesado binario  de training y de validación \n",
    "binary_bow_tr=build_binary_bow(tr_txt,dict_freq,dict_indices)\n",
    "binary_boW_validacion=build_binary_bow(val_txt,dict_freq,dict_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos las bolsas de palabras con pesado frecuencia de training y de validación \n",
    "frequency_bow_tr=build_freq_bow(tr_txt,dict_freq,dict_indices)\n",
    "frequency_boW_validacion=build_freq_bow(val_txt,dict_freq,dict_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos las bolsas de palabras con pesado tfidf de training y de validación \n",
    "tfidf_bow_tr=build_tfidf_bow(tr_txt,dict_freq,dict_indices)\n",
    "tfidf_boW_validacion=build_tfidf_bow(val_txt,dict_freq,dict_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Diferencias en bolsa de palabras\n",
    "\n",
    "veamos la diferencia entre los pesos con cada esquema para un caso particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el token @USUARIO corresponde al lugar 9 en el diccionario de frecuencias \n",
      "el primer tweet de los datos (es decir el documento 0) contiene tres veces este token\n",
      "El peso w_(0,9) es:\n",
      "con pesado binario: 1\n",
      "con pesado de frecnuencia: 3\n",
      "con pesado de tfidf: 5\n"
     ]
    }
   ],
   "source": [
    "#el token \"\"@USUARIO\"\" corresponde al lugar 9 en el diccionario de frecuencias \n",
    "x=dict_indices.get(\"@USUARIO\")\n",
    "print(\"el token \"\"@USUARIO\"\" corresponde al lugar\",x, \"en el diccionario de frecuencias \")\n",
    "print(\"el primer tweet de los datos (es decir el documento 0) contiene tres veces este token\")\n",
    "print(\"El peso w_(0,9) es:\")\n",
    "print(\"con pesado binario:\",binary_bow_tr[0][9])\n",
    "print(\"con pesado de frecnuencia:\", frequency_bow_tr[0][9])\n",
    "print(\"con pesado de tfidf:\", tfidf_bow_tr[0][9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Clasificador}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[356  62]\n",
      " [ 49 120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       418\n",
      "           1       0.66      0.71      0.68       169\n",
      "\n",
      "    accuracy                           0.81       587\n",
      "   macro avg       0.77      0.78      0.77       587\n",
      "weighted avg       0.82      0.81      0.81       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#llamamos al clasificador y le pasamos la bolsa de palabras binaria y las etiqutas\n",
    "grid.fit(binary_bow_tr,tr_labels)\n",
    "\n",
    "#predicción\n",
    "y_pred_binary=grid.predict(binary_boW_validacion)\n",
    "\n",
    "#medidas, reporte de clasificación,matriz de confusión\n",
    "print(confusion_matrix(val_labels,y_pred_binary))\n",
    "print(metrics.classification_report(val_labels,y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ely/Documents/Maestria/segundo_semestre/cimat2023-1/lenguaje/.conda/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/ely/Documents/Maestria/segundo_semestre/cimat2023-1/lenguaje/.conda/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[362  56]\n",
      " [ 45 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88       418\n",
      "           1       0.69      0.73      0.71       169\n",
      "\n",
      "    accuracy                           0.83       587\n",
      "   macro avg       0.79      0.80      0.79       587\n",
      "weighted avg       0.83      0.83      0.83       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#llamamos al clasificador y le pasamos la bolsa de palabras de frecuencia y las etiqutas\n",
    "grid.fit(frequency_bow_tr,tr_labels)\n",
    "\n",
    "#predicción\n",
    "y_pred_frequency=grid.predict(frequency_boW_validacion)\n",
    "\n",
    "#medidas, reporte de clasificación,matriz de confusión\n",
    "print(confusion_matrix(val_labels,y_pred_frequency))\n",
    "print(metrics.classification_report(val_labels,y_pred_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llamamos al clasificador y le pasamos la bolsa de palabras binaria y las etiqutas\n",
    "grid.fit(binary_bow_tr,tr_labels)\n",
    "\n",
    "#predicción\n",
    "y_pred_binary=grid.predict(binary_boW_validacion)\n",
    "\n",
    "#medidas, reporte de clasificación,matriz de confusión\n",
    "print(confusion_matrix(val_labels,y_pred_binary))\n",
    "print(metrics.classification_report(val_labels,y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizacion_dos(X):\n",
    "    norm = LA.norm(X, ord=2, axis=1)\n",
    "\n",
    "    filas = np.shape(X)[0]\n",
    "    columnas = np.shape(X)[1]\n",
    "\n",
    "    for i in range(filas) :\n",
    "        for j in range(columnas) :\n",
    "            X[i][j] =  X[i][j] / norm[i]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color='lightblue'>\n",
    "\n",
    "4,5,6. Evalue BoW con pesado binario, de frecuencia y tfidf con normalizado l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Bolsas de palabras con distintos equemas de pesado con normalizado L2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color='lightblue'>\n",
    "\n",
    "7. Ponga una tabla comparativa a modo de resumen con las seis entradas anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color='lightblue'>\n",
    "\n",
    "8. De las configuraciones anteriores elija la mejor y evalúela con más y menos términos (e.g., 1000 y 7000). Ponga una tabla dónde compare las tres configuraciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color='lightblue'>\n",
    "\n",
    "9. Utilice el recurso léxico del Consejo Nacional de Investigación de Canadá llamado \"EmoLex\" (https://www.saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm) para construir una \"Bolsa de Emociones\" de los Tweets de agresividad (Debe usar EmoLex en Español). Para esto, una estrategia sencilla sería enmascarar cada palabra con su emoción, y después construir la Bolsa de Emociones (BoE).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color='lightblue'>\n",
    "\n",
    "10. Evalúa tú BoE clasificando con SVM. Ponga una tabla comparativa a modo de resumen con los tres pesados, normalize cada uno si lo cree conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4.5 color='lightblue'>\n",
    "\n",
    "$\\textit{Ejercicio 3. Recurso Línguistico de Emociones Mexicano}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color='lightblue'>\n",
    "\n",
    "11. Utiliceelrecursoléxicollamado\"SpanishEmotionLexicon(SEL)\"delDr.GrigoriSidorov, profesor del Centro de Investigación en Computación (CIC) del Instituto Politécnico Nacional (http://www.cic.ipn.mx/∼sidorov/), para enmascarar cada palabra con su emo- ción, y después construir la Bolsa de Emociones con algún pesado (e.g., binario, tf, tfidf). Proponga alguna estrategia para incorporar el \"valor\" del \"Probability Factor of Affective use\" en su representación vectorial del documento. Evalúa y escribe una tabla compara- tiva a modo de resumen con al menos tres pesados: binario, frecuencia, tfidf. Normalize cada pesado según lo crea conveniente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color='lightblue'>\n",
    "\n",
    "12. En un comentario aparte, discuta sobre la estrategía que utilizó para incorporar el \"Probability Factor of Affective use\". No más de 5 renglones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4.5 color='lightblue'>\n",
    "\n",
    "$\\textit{Ejercicio 4. ¿Podemos mejorar con Bigramas?}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color='lightblue'>\n",
    "\n",
    "13. Hacer un experimento dónde concatene una buena BoW según sus experimentos anteri- ores con otra BoW construida a partir de los 1000 bigramas más frecuentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color='lightblue'>\n",
    "\n",
    "14. Hacer un experimento con las Bolsas de Emociones, Bolsa de Palabras y Bolsa de Bi- gramas; usted elige las dimensionalidades. Para construir la representación final del documento utilice la concatenación de las representaciones según sus observaciones (e.g., Bolsa de Palabras + Bolsa de Bigramas + Bolsa de Sentimientos de Canadá + Bolsa de Sentimientos de Grigori), y aliméntelas a un SVM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2.5 color='lightblue'>\n",
    "\n",
    "15. Elabore conclusiones sobre toda esta Tarea, incluyendo observaciones, comentarios y posibles mejoras futuras. Discuta el comportamiento de la BoW de usar solo palabras a integrar bigramas, y luego a integrar todo ¿ayudó? o ¿empeoró?. Discuta también brevemente el costo computacional de los experimentos ¿Valió la Pena tener todo?. Sea breve: todo en NO más de dos párrafos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
