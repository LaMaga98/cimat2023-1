{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{PLN. Tarea 4: Modelos de Lenguaje Estadísticos}$$\n",
    "$$\\textit{Y. Sarahi García Gozález}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4.5 color='lightblue'>\n",
    "\n",
    "$\\textit{Librerías}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log10,log2\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from itertools import combinations\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,precision_recall_fscore_support,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea realizada en MacOs. \n",
      "Las versiones de las librerías y de python utilizadas fueron:\n",
      "\n",
      "Python version: 3.11.0\n",
      "NumPy version: 1.23.5\n",
      "NLTK version: 3.8.1\n",
      "Pandas version: 2.1.4\n",
      "Scikit-learn version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tarea realizada en MacOs. \\nLas versiones de las librerías y de python utilizadas fueron:\\n\")\n",
    "from platform import python_version\n",
    "print(\"Python version:\", python_version())\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"NLTK version:\", nltk.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Scikit-learn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<font size=4.5 color='lightblue'>\n",
    "\n",
    "$\\textit{Modelo de lenguaje y evaluación}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definiremos las funciones para cargar la lista de documentos y los diccionarios necesarios para crear el corpus y el vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_file(path_corpus,path_truth):\n",
    "\n",
    "    tr_txt=[]\n",
    "    tr_labels=[]\n",
    "\n",
    "    with open(path_corpus, \"r\") as f_corpus,open(path_truth, \"r\") as f_truth:\n",
    "        for tweet in f_corpus:\n",
    "            tr_txt += [tweet]\n",
    "        for label in f_truth:\n",
    "            tr_labels += [label]   \n",
    "             \n",
    "    return tr_txt, tr_labels\n",
    "\n",
    "def create_dic_freq(corpus,n):\n",
    "    fdist = nltk.FreqDist(corpus)\n",
    "    aux=[(fdist[key],key) for key in fdist]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    aux=aux[:n]\n",
    "\n",
    "    return aux\n",
    "\n",
    "def create_dic_ranking(dic_freq):\n",
    "    dict_indices=dict()\n",
    "    cont = 0\n",
    "    for weight, word in dic_freq:\n",
    "        dict_indices[word]= cont\n",
    "        cont+= 1\n",
    "\n",
    "    return dict_indices\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Funcion que crea un corpus con palabras en minusculas y con los caracteres especiales ###### \n",
    "###### <s> al inicio del tuit t </s> al final del tuit ###### \n",
    "def create_corpus_from_text(tuit_list,tokenizer):\n",
    "\n",
    "    ''' Funcion que crea un corpus con palabras en minusculas\n",
    "        y con los caracteres especiales\n",
    "       <s> al inicio del tuit t </s> al final del tuit\n",
    "       \n",
    "        parametros: \n",
    "        -lista de tuits (o documentos en general)\n",
    "        -tokenizador\n",
    "        returns:\n",
    "        -corpus con todos los documentos tokenizados (se indica el iniciio y fin de cada uno\n",
    "         con los caracteres especiales <s>,</s>)\n",
    "       \n",
    "    '''\n",
    "\n",
    "    corpus_palabras = []\n",
    "\n",
    "    for tuit in tuit_list:\n",
    "        #minúsculas\n",
    "        tuit = tuit.lower()\n",
    "        # token especial <s> al inicio del tuit\n",
    "        tuit = \"<s> \" + tuit\n",
    "        #token especial </s> al final del tuit\n",
    "        tuit += \" </s>\"\n",
    "        #tokenizaos el tuit y agregar las palabras al corpus\n",
    "        corpus_palabras.extend(tokenizer.tokenize(tuit))\n",
    "\n",
    "    return corpus_palabras\n",
    "\n",
    "\n",
    "def create_vocabulary(dictionary_freq,freq_umbral):\n",
    "    '''\n",
    "    Función que crea el vocabulario a partir de un diccionario de frecuencias,\n",
    "    sólo se toman las palabras con frecuencia mayor o igual a freq_umbral\n",
    "    '''\n",
    "\n",
    "    #palabras con una frecuencia igual o mayor que el umbral\n",
    "    vocabulario = [palabra for palabra, frecuencia in dictionary_freq.items() if frecuencia >= freq_umbral]\n",
    "    #token especial <unk> para las palabras desconocidas\n",
    "    vocabulario.append(\"<unk>\")\n",
    "    return vocabulario\n",
    "\n",
    "\n",
    "\n",
    "def enmascarar(corpus, vocabulario):\n",
    "    # Enmascarar las palabras desconocidas con <unk>\n",
    "    corpus_enmascarado = [palabra if palabra in vocabulario else \"<unk>\" for palabra in corpus]\n",
    "    \n",
    "    return corpus_enmascarado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardamos los textos de entrenamiento y validación\n",
    "tr_txt,tr_labels=get_text_from_file(\"/Users/ely/Documents/Maestria/segundo_semestre/cimat2023-1/lenguaje/practicas/03_practica/mex20_train.txt\",\"/Users/ely/Documents/Maestria/segundo_semestre/cimat2023-1/lenguaje/practicas/03_practica/mex20_train_labels.txt\")\n",
    "val_txt,val_labels=get_text_from_file(\"/Users/ely/Documents/Maestria/segundo_semestre/cimat2023-1/lenguaje/practicas/03_practica/mex20_val.txt\",\"/Users/ely/Documents/Maestria/segundo_semestre/cimat2023-1/lenguaje/practicas/03_practica/mex20_val_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizamos\n",
    "tokenizer=TweetTokenizer()\n",
    "#Generamos el corpus\n",
    "corpus=create_corpus_from_text(tr_txt,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer tuit del corpus:\n",
      "<s> @usuario @usuario @usuario q se puede esperar del maricon de closet de la yañez aun recuerdo esa ves q lo vi en zona rosa viendo quien lo levantada </s>\n"
     ]
    }
   ],
   "source": [
    "#imprimimos el primer tuit con los tokens especiales d einciio y fin\n",
    "inicio= corpus.index(\"<s>\")\n",
    "fin= corpus.index(\"</s>\", inicio)\n",
    "primer_tuit = \" \".join(corpus[inicio : fin+1])\n",
    "\n",
    "print(\"Primer tuit del corpus:\")\n",
    "print(primer_tuit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4.5 color='lightblue'>\n",
    "\n",
    "$\\textit{Generación de Texto}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4.5 color='lightblue'>\n",
    "\n",
    "$\\textit{El ahorcado}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
