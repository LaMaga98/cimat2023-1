{"cells":[{"cell_type":"markdown","metadata":{"id":"kbg9i1ijC1px"},"source":["#INTRODUCCIÓN A PYTORCH\n","\n","### Sesión 1  \n","\n","Contenido:\n","* Tensores\n","* Manejo de tensores\n","* Operaciones con tensores\n","* Autogradiente\n","* Optimización durante el entrenamiento de algún modelo\n","* Ejemplo 1: Regresión Logística\n"]},{"cell_type":"markdown","metadata":{"id":"Tw55MzgPDESn"},"source":["**Instalación**:https://pytorch.org/get-started/locally/"]},{"cell_type":"markdown","metadata":{"id":"2Y_1CyxSEQ9-"},"source":["# Tensores"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1934,"status":"ok","timestamp":1709952763957,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"PAlsVPCNCogh"},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","metadata":{"id":"6HKIrTwTEbEj"},"source":["El tipo de variable más básico de la librería es el tensor. En pytorch, todo está basado en tensores. Un tensor puede tener diferentes dimensiones, puede ser 1d, 2d, 3d, 4d, etc.\n","\n","`torch.tensor(data, dtype=None, device=None, requires_grad=False)`\n","\n","**Parameters:**\n","\n","* `data` (`array_like`): los datos para el tensor\n","* `dtype` (`torch.dtype`): el tipo de dato del tensor. Cuando es `None` infiere el tipo de dato. Otros tipos pueden ser: `torch.int`, `torch.float`, `torch.double`, etc...\n","* `device` (`torch.device`): el dispositivo donde el tensor se va a almacenar (CPU o GPU).\n","* `requires_grad` (`bool`): si el autogradiente debe acumular operaciones con el tensor.\n","\n","**Returns:**\n","\n","* torch.Tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709749728506,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"T17MRSDiFeSh","outputId":"976a8186-5578-4e95-d6c6-9088a38dbb54"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","INICIALIZADO\n","Tensor: tensor(1.) \n","shape: torch.Size([]) \n","dtype: torch.float32 \n","device: cpu \n","requires_grad: False\n"]}],"source":["# Tensor Escalar\n","\n","print('\\nINICIALIZADO')\n","x = torch.tensor(1.0)\n","print('Tensor:', x, '\\nshape:', x.shape, '\\ndtype:', x.dtype, '\\ndevice:', x.device, '\\nrequires_grad:', x.requires_grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1708727756913,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"42pl4l48GsFp","outputId":"9e14af78-ab94-44bc-9ad6-13cc4150f4f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["SIN INICIALIZAR\n","Tensor: tensor([-2.3254e-05,  3.1480e-41, -2.3207e-05]) \n","shape: torch.Size([3]) \n","dtype: torch.float32 \n","device: cpu \n","requires_grad: False\n","\n","INICIALIZADO\n","Tensor: tensor([1, 2, 3]) \n","shape: torch.Size([3]) \n","dtype: torch.int64 \n","device: cpu \n","requires_grad: False\n"]}],"source":["# Lista\n","\n","print('SIN INICIALIZAR')\n","x = torch.empty(3) # vector, 1D\n","print('Tensor:', x, '\\nshape:', x.shape, '\\ndtype:', x.dtype, '\\ndevice:', x.device, '\\nrequires_grad:', x.requires_grad)\n","\n","print('\\nINICIALIZADO')\n","x = torch.tensor([1,2,3])\n","print('Tensor:', x, '\\nshape:', x.shape, '\\ndtype:', x.dtype, '\\ndevice:', x.device, '\\nrequires_grad:', x.requires_grad)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208,"status":"ok","timestamp":1709948326365,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"9usTiIeIHQ9G","outputId":"e863b71c-934e-4a73-b0ae-a10256b5e01e"},"outputs":[{"name":"stdout","output_type":"stream","text":["SIN INICIALIZAR\n","tensor([[2.1707e-18, 7.0952e+22, 1.7748e+28],\n","        [1.8176e+31, 7.2708e+31, 5.0778e+31]])\n","torch.Size([2, 3])\n","\n","INICIALIZADO\n","tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","torch.Size([2, 3])\n"]}],"source":["# Matriz\n","\n","print('SIN INICIALIZAR')\n","x = torch.empty(2,3)\n","print(x)\n","print(x.shape)\n","\n","print('\\nINICIALIZADO')\n","x = torch.tensor([[1,2,3],\n","                  [4,5,6]])\n","print(x)\n","print(x.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":405,"status":"ok","timestamp":1708728787730,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"aczo4ooDKuVH","outputId":"0b1f5a0a-ffe0-400b-8ea3-91e6edd52e1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[-2.7040e+07,  3.1484e-41, -2.0594e-08],\n","         [ 3.1480e-41,  0.0000e+00,  1.1755e-38]],\n","\n","        [[-2.0594e-08,  3.1480e-41,  2.0000e+00],\n","         [ 0.0000e+00,  1.7347e-18,  0.0000e+00]]])\n"]}],"source":["# Tensor, 3 dimensiones\n","x = torch.empty(2,2,3)\n","print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":161,"status":"ok","timestamp":1709749902077,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"rH5LBOqhHoRN","outputId":"401dfa4c-ce70-46a0-ea1c-89aba61da5be"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[0., 0.],\n","         [0., 0.]],\n","\n","        [[0., 0.],\n","         [0., 0.]]], dtype=torch.float64)\n","tensor([[[0., 0.],\n","         [0., 0.]],\n","\n","        [[0., 0.],\n","         [0., 0.]]], dtype=torch.float64)\n"]}],"source":["# Numpy array\n","\n","import numpy as np\n","\n","x = torch.tensor(np.zeros((2,2,2)))\n","print(x)\n","\n","a = np.zeros((2,2,2))\n","x = torch.from_numpy(a)\n","print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1709749927263,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"-2HNIO59JfA5","outputId":"bc163454-44bd-407f-f6e5-224284f092fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Aleatorio\n","tensor([[0.7901, 0.2855, 0.4613],\n","        [0.6088, 0.4174, 0.2413],\n","        [0.7654, 0.0757, 0.1759],\n","        [0.7412, 0.5980, 0.8185],\n","        [0.1009, 0.6727, 0.6542]])\n","Tensor con ceros\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])\n","Tensor con unos\n","tensor([[[1.],\n","         [1.],\n","         [1.]],\n","\n","        [[1.],\n","         [1.],\n","         [1.]],\n","\n","        [[1.],\n","         [1.],\n","         [1.]],\n","\n","        [[1.],\n","         [1.],\n","         [1.]],\n","\n","        [[1.],\n","         [1.],\n","         [1.]]])\n"]}],"source":["# Otras inicializaciones\n","\n","print(\"Aleatorio\")\n","x = torch.rand(5, 3) # torch.rand(size)\n","print(x)\n","\n","print(\"Tensor con ceros\")\n","x = torch.zeros(5, 3)\n","print(x)\n","\n","print(\"Tensor con unos\")\n","x = torch.ones(5, 3, 1)\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"G4krpoMBTQ_A"},"source":["## Manejo de tensores"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1708729778179,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"llsVFspXMRyl","outputId":"f4ff4b96-909f-47a4-e86a-91c4370c6464"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.2081, 0.7382, 0.2948],\n","        [0.3076, 0.7349, 0.5252],\n","        [0.8045, 0.7692, 0.5562],\n","        [0.7235, 0.6615, 0.2222],\n","        [0.5747, 0.0781, 0.5640]])\n","tensor([0.2081, 0.3076, 0.8045, 0.7235, 0.5747])\n","tensor([0.3076, 0.7349, 0.5252])\n","tensor(0.7349)\n","0.7348912954330444\n"]}],"source":["# Slicing\n","x = torch.rand(5,3)\n","print(x)\n","print(x[:, 0])\n","print(x[1, :])\n","print(x[1,1])\n","\n","# Obtener el valor si solo hay un elemento en el tensor\n","print(x[1,1].item())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1708729968335,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"D_1y3wzhOzy1","outputId":"cf212e6c-4799-4794-a0de-b6d0ea3f70b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) torch.Size([2, 2, 4])\n"]}],"source":["# Reshape con torch.view()\n","x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)  # Con -1, pytorch determina la dimensión con base en el tamaño, automáticamente.\n","w = x.view(2,2,-1)\n","print(x.size(), y.size(), z.size(), w.size())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1708730781834,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"TxmB6jCyPU1Q","outputId":"d0229ad9-75de-4f37-bc1d-45c464f806ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1., 1., 1., 1., 1.])\n","[1. 1. 1. 1. 1.]\n","<class 'numpy.ndarray'>\n"]}],"source":["# De torch.tensor a numpy.array\n","a = torch.ones(5)\n","print(a)\n","b = a.numpy() # <----\n","print(b)\n","print(type(b))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1709949655805,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"DowQBfqYTZ30","outputId":"69179534-4773-4590-a441-d67eecf959b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["# CPU o GPU\n","# Por default, todos los tensores son creados en CPU\n","# Si está disponible, podemos moverlos a GPU\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")          # CUDA device object\n","    print(device)\n","\n","    y = torch.ones_like(x, device=device)  # Crear tensor en GPU\n","    x = x.to(device)\n","    z = x + y\n","    # z = z.numpy()    # error porque numpy no soporta tensores en GPU\n","    z = z.to(\"cpu\")       # mover a cpu\n","    z = z.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":728,"status":"ok","timestamp":1709750266160,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"cjYNj6GOUaQB","outputId":"9571bd85-b0e1-4924-b95e-9cfa87ca6010"},"outputs":[{"name":"stdout","output_type":"stream","text":["device: cuda:0 \n","number of gpus: 1 \n","name of gpu: Tesla T4\n","consumo de VRAM: 0.0 GB\n"]}],"source":["\n","# tensor que se guarda en RAM\n","x = torch.tensor(np.zeros((10000, 10000)))\n","\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","print('device:', device,\n","      '\\nnumber of gpus:', torch.cuda.device_count(),\n","      '\\nname of gpu:', torch.cuda.get_device_name(0))\n","print('consumo de VRAM:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')"]},{"cell_type":"markdown","metadata":{"id":"NOBYF2Q3S1qZ"},"source":["## Operaciones con tensores"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162,"status":"ok","timestamp":1709750286325,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"bLMyYwzkS2Cw","outputId":"6b413ed5-df0c-4995-a6db-6b237bdd748c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 2., 3.],\n","        [4., 5., 6.],\n","        [7., 8., 9.]], dtype=torch.float64)\n","tensor([[1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.]], dtype=torch.float64)\n"]}],"source":["A = torch.tensor([[1,2,3],\n","                  [4,5,6],\n","                  [7,8,9]], dtype = torch.float64)\n","\n","print(A)\n","\n","B = torch.tensor([[1,0,0],\n","                  [0,1,0],\n","                  [0,0,1]], dtype = torch.float64)\n","\n","print(B)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":178,"status":"ok","timestamp":1709750287678,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"EPiNBy9aTCkI","outputId":"f2f06197-fb92-4000-d5a4-ecd104212c75"},"outputs":[{"name":"stdout","output_type":"stream","text":["A+B = tensor([[ 2.,  2.,  3.],\n","        [ 4.,  6.,  6.],\n","        [ 7.,  8., 10.]], dtype=torch.float64) \n","\n","A*B = tensor([[1., 0., 0.],\n","        [0., 5., 0.],\n","        [0., 0., 9.]], dtype=torch.float64) \n","\n","AB = tensor([[1., 2., 3.],\n","        [4., 5., 6.],\n","        [7., 8., 9.]], dtype=torch.float64) \n","\n","A^2 = tensor([[ 1.,  4.,  9.],\n","        [16., 25., 36.],\n","        [49., 64., 81.]], dtype=torch.float64) \n","\n","A^T = tensor([[1., 4., 7.],\n","        [2., 5., 8.],\n","        [3., 6., 9.]], dtype=torch.float64) \n","\n"]}],"source":["print('A+B =', A+B, '\\n')\n","print('A*B =', A*B, '\\n')\n","print('AB =', torch.matmul(A,B), '\\n')\n","print('A^2 =', A**2, '\\n')\n","print('A^T =', torch.transpose(A, 0, 1), '\\n')"]},{"cell_type":"markdown","metadata":{"id":"bXJ02OiVV9_A"},"source":["## Autogradiente"]},{"cell_type":"markdown","metadata":{"id":"dKP-gpz7WPVH"},"source":["Con el parámetro ***requires_grad*** se le señala a pytorch que se requerirá calcular gradientes para ese tensor en particular. Es decir, se señala la variable que se quiere optimizar en algún modelo. Provee de diferenciación automática para todas las operaciones en el tensor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvLSzmGQV6Va"},"outputs":[],"source":["x = torch.tensor([5.5, 3], requires_grad=True)  # requires_grad = True -> registra todas las operaciones en el tensor\n"]},{"cell_type":"markdown","metadata":{"id":"NHKSvkzm4Ddo"},"source":["\n","Dada la función\n","\n","$ y = f(a,x,b) = ax^2 + b $,\n","\n","sus derivadas parciales y gradiente son\n","\n","$ \\dfrac{dy}{da} = x^2, \\quad \\dfrac{dy}{dx} = 2ax, \\quad \\dfrac{dy}{db} = 1, \\quad \\nabla y(a,x,b) = (x^2,2ax,1)  $\n","\n","así que evaluando el gradiente en el punto (2,1,1) se tiene que\n","\n","$ \\nabla y(2,1,1) = (1,4,1)  $\n","\n","**Vamos a calcular este gradiente de forma numérica utilizando el autograd de PyTorch.**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143,"status":"ok","timestamp":1709060548079,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"xc0tKuE3V7p1","outputId":"1025d5c4-5bfa-427f-8a1c-509686d4d794"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(1., dtype=torch.float64, requires_grad=True)\n","None\n","tensor(3., dtype=torch.float64, grad_fn=<AddBackward0>)\n","<AddBackward0 object at 0x7e5bc9fedea0>\n"]}],"source":["a = torch.tensor(2, dtype = torch.float64, requires_grad = False)\n","x = torch.tensor(1, dtype = torch.float64, requires_grad = True)\n","b = torch.tensor(1, dtype = torch.float64, requires_grad = False)\n","\n","\n","y = a*x**2 + b # La variable \"y\" fue creada como resultado de una operación con \"x\", por lo que \"y\" contiene un atributo grad_fn.\n","               # (grad_fn hace referencia a una función que ha creado el tensor)\n","\n","print(x)\n","print(x.grad_fn) # creada por el usuario -> grad_fn = None\n","print(y)\n","print(y.grad_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":664},"executionInfo":{"elapsed":6227,"status":"ok","timestamp":1709060558334,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"Gn5QZt084om9","outputId":"8758652d-3e8e-4629-c21d-dd314d7b3e00"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.1.0+cu121)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n"]},{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.43.0 (0)\n"," -->\n","<!-- Title: %3 Pages: 1 -->\n","<svg width=\"109pt\" height=\"326pt\"\n"," viewBox=\"0.00 0.00 109.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n","<title>%3</title>\n","<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-322 105,-322 105,4 -4,4\"/>\n","<!-- 138932722598192 -->\n","<g id=\"node1\" class=\"node\">\n","<title>138932722598192</title>\n","<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n","</g>\n","<!-- 138932696044912 -->\n","<g id=\"node2\" class=\"node\">\n","<title>138932696044912</title>\n","<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n","</g>\n","<!-- 138932696044912&#45;&gt;138932722598192 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>138932696044912&#45;&gt;138932722598192</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n","</g>\n","<!-- 138932694679616 -->\n","<g id=\"node3\" class=\"node\">\n","<title>138932694679616</title>\n","<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n","</g>\n","<!-- 138932694679616&#45;&gt;138932696044912 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>138932694679616&#45;&gt;138932696044912</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n","</g>\n","<!-- 138932694679808 -->\n","<g id=\"node4\" class=\"node\">\n","<title>138932694679808</title>\n","<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-196 6,-196 6,-177 95,-177 95,-196\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n","</g>\n","<!-- 138932694679808&#45;&gt;138932694679616 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>138932694679808&#45;&gt;138932694679616</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-169.8 50.5,-159.85 50.5,-151.13\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.09 50.5,-141.09 47,-151.09 54,-151.09\"/>\n","</g>\n","<!-- 138932694679952 -->\n","<g id=\"node5\" class=\"node\">\n","<title>138932694679952</title>\n","<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n","</g>\n","<!-- 138932694679952&#45;&gt;138932694679808 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>138932694679952&#45;&gt;138932694679808</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.75C50.5,-224.8 50.5,-214.85 50.5,-206.13\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.09 50.5,-196.09 47,-206.09 54,-206.09\"/>\n","</g>\n","<!-- 138932694562464 -->\n","<g id=\"node6\" class=\"node\">\n","<title>138932694562464</title>\n","<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-318 23.5,-318 23.5,-287 77.5,-287 77.5,-318\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n","</g>\n","<!-- 138932694562464&#45;&gt;138932694679952 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>138932694562464&#45;&gt;138932694679952</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.92C50.5,-279.22 50.5,-269.69 50.5,-261.43\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.25 50.5,-251.25 47,-261.25 54,-261.25\"/>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.graphs.Digraph at 0x7e5bc9fefa30>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["! pip install torchviz\n","from torchviz import make_dot\n","\n","make_dot(y)"]},{"cell_type":"markdown","metadata":{"id":"QcJ0l_i37HO_"},"source":["Calculemos los gradientes con backpropagation:\n","\n","\n","\n","*   Al terminar todas las operaciones que se le aplicarán al tensor, se puede llamar al método .backward(), que calculará todos los gradientes automáticamente.\n","*   La derivada parcial de la función con respecto al tensor se acumulará en el atributo .grad"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146,"status":"ok","timestamp":1709060561687,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"GUVpg8za6Son","outputId":"6ac27a22-f9bf-41f1-ea28-b30879ef0f9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["dy/dx =  tensor(4., dtype=torch.float64)\n"]}],"source":["y.backward()\n","print('dy/dx = ', x.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1709060568100,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"vtvIEL6B8Sur","outputId":"8077ccf3-561f-443f-f92b-d2967d8e5b38"},"outputs":[{"name":"stdout","output_type":"stream","text":["dy/da =  None\n","dy/db =  None\n"]}],"source":["print('dy/da = ', a.grad)\n","print('dy/db = ', b.grad)"]},{"cell_type":"markdown","metadata":{"id":"26VUkAfl9o5O"},"source":["### Optimización durante el entrenamiento de algún modelo\n","\n","Durante el ciclo de entrenamiento, se realizan operaciones con los pesos del modelo y después se requiere **actualizar** los pesos calculados (optimización). Esta operación de actualización de pesos **no debe acumularse** en el gradiente. Para solucionarlo, existen varias alternativas:\n","\n","*  x.requires_grad_(False) $ \\quad$  ----> cambia la bandera existente 'in-place'\n","*  x.detach()             $ \\quad$ ----> obtener un nuevo tensor con el mismo contenido pero sin cálculos de gradiente.\n","*  with torch.no_grad():   $ \\quad$----> envolver instrucciones en 'with torch.no_grad():'\n","\n","\n","Además, .backward() acumula el gradiente para el tensor en el atributo .grad, por lo que se debe ser cuidadoso durante la optimización.\n","\n","Se utiliza\n","> .zero_()\n","\n","para **vaciar la acumulación del gradiente** antes de un nuevo paso de optimización."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":638,"status":"ok","timestamp":1709068865551,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"-ss0z9FV8rJF","outputId":"5c31f7c7-080b-4f66-8645-cb57056c704f"},"outputs":[{"name":"stdout","output_type":"stream","text":["weights - epoch 0: tensor([6., 6., 6., 6.])\n","weights - epoch 1: tensor([2.4000, 2.4000, 2.4000, 2.4000])\n","weights - epoch 2: tensor([0.9600, 0.9600, 0.9600, 0.9600])\n","tensor([0.0640, 0.0640, 0.0640, 0.0640], requires_grad=True)\n","tensor(0.3072, grad_fn=<SumBackward0>)\n","tensor([0., 0., 0., 0.])\n"]}],"source":["# Ejemplo dummy\n","\n","weights = torch.ones(4, requires_grad=True)\n","\n","for epoch in range(3):\n","    model_output = (3*weights**2).sum() # Operaciones\n","    model_output.backward()\n","\n","    print(f\"weights - epoch {epoch}: {weights.grad}\")\n","\n","    # Optimizar modelo, actualizar pesos. (En la práctica, estos pasos se suelen hacer automaticamente por medio de implementaciones en la librería)\n","    with torch.no_grad():\n","        weights -= 0.1 * weights.grad\n","\n","    # Vaciar gradiente\n","    weights.grad.zero_()\n","\n","print(weights)\n","print(model_output)\n","print(weights.grad)"]},{"cell_type":"markdown","metadata":{"id":"WS7gWdI7YFjS"},"source":["Los algoritmos de optimización implementados en la librería (ejemplo: torch.optim.SGD) incluyen el método zero_grad() para reiniciar la acumulación de gradientes:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709069175861,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"VfbuOivxChnT","outputId":"4893238b-7505-4c5b-8c15-cfc4b7d4183c"},"outputs":[{"name":"stdout","output_type":"stream","text":["weights.grad, antes de reiniciar acumulacion de grad:  tensor([0.0016, 0.0016, 0.0016, 0.0016])\n","\n","weights:  tensor([0.0001, 0.0001, 0.0001, 0.0001], requires_grad=True)\n","\n","model_output:  tensor(8.2463e-07, grad_fn=<SumBackward0>)\n","\n","weights.grad, después de reiniciar acumulacion de grad:  None\n"]}],"source":["# Optimizador SGD\n","optimizer = torch.optim.SGD([weights], lr=0.1)\n","# Durante el entrenamiento:\n","model_output = (3*weights**2).sum()\n","model_output.backward()\n","optimizer.step()  # <-------\n","\n","print(\"weights.grad, antes de reiniciar acumulacion de grad: \", weights.grad)\n","\n","optimizer.zero_grad() # <-------\n","\n","\n","print('\\nweights: ', weights)\n","print('\\nmodel_output: ', model_output)\n","print(\"\\nweights.grad, después de reiniciar acumulacion de grad: \", weights.grad)"]},{"cell_type":"markdown","metadata":{"id":"vcWZ_AEjkKQ0"},"source":["# Ejemplo 1: Regresión logística\n","\n","0) Preparar datos  \n","1) Definir modelo  \n","2) Función de pérdida (loss) y optimizador  \n","3) Ciclo de entrenamiento  \n","4) Evaluación del modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"koIN05ffq4xi"},"outputs":[],"source":["#### EJERCICIO DE CÓDIGO PARA LA AYUDANTÍA #####\n","\n","# COMPLETAR EL CÓDIGO\n","\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","# 0) Preparar datos\n","bc = datasets.load_breast_cancer()\n","X, y = bc.data, bc.target\n","\n","n_samples, n_features = X.shape\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n","\n","# scale\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Array a Tensor\n","\n","\n","\n","# Cambiar dimensión\n","\n","\n","# 1) Definir modelo\n","#  lineal: f = wx + b , sigmoide al final\n","class Model(nn.Module):\n","    def __init__(self, n_input_features):\n","        super(Model, self).__init__()\n","        self.linear = nn.Linear(n_input_features, 1)\n","\n","    def forward(self, x):\n","        y_pred = torch.sigmoid(self.linear(x))\n","        return y_pred\n","\n","model = Model(n_features)\n","\n","# 2) Función de pérdida (loss) y optimizador\n","num_epochs = 100\n","learning_rate = 0.01\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","# 3) Ciclo de entrenamiento\n","for epoch in range(num_epochs):\n","    # Forward pass\n","\n","\n","    # Loss\n","\n","\n","    # Backward pass\n","\n","\n","    # Update\n","\n","\n","    # ?\n","\n","\n","\n","    if (epoch+1) % 10 == 0:\n","        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n","\n","\n","# 4) Evaluación del modelo\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11134,"status":"ok","timestamp":1709956821927,"user":{"displayName":"Judith Tavarez Rodríguez","userId":"15492812147513935063"},"user_tz":360},"id":"iAJk2dI0ldQc","outputId":"5b4e8417-a8ac-4a3a-aca3-e60d0809f8fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 10, loss = 0.4409\n","epoch: 20, loss = 0.3901\n","epoch: 30, loss = 0.3531\n","epoch: 40, loss = 0.3247\n","epoch: 50, loss = 0.3021\n","epoch: 60, loss = 0.2837\n","epoch: 70, loss = 0.2683\n","epoch: 80, loss = 0.2552\n","epoch: 90, loss = 0.2439\n","epoch: 100, loss = 0.2340\n","accuracy: 0.9035\n"]}],"source":["#### CÓDIGO SOLUCIÓN DEL EJERCICIO ANTERIOR ######\n","\n","import torch\n","import torch.nn as nn # Siguiente ayudantía comentamos sobre torch.nn\n","import numpy as np\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","# 0) Preparar datos\n","bc = datasets.load_breast_cancer()\n","X, y = bc.data, bc.target\n","\n","n_samples, n_features = X.shape\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n","\n","# scale\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Array a Tensor\n","X_train = torch.from_numpy(X_train.astype(np.float32))\n","X_test = torch.from_numpy(X_test.astype(np.float32))\n","y_train = torch.from_numpy(y_train.astype(np.float32))\n","y_test = torch.from_numpy(y_test.astype(np.float32))\n","\n","# Cambiar dimensión\n","y_train = y_train.view(y_train.shape[0], 1)\n","y_test = y_test.view(y_test.shape[0], 1)\n","\n","\n","# 1) Definir modelo\n","#  lineal: f = wx + b , sigmoide al final\n","class Model(nn.Module):\n","    def __init__(self, n_input_features):\n","        super(Model, self).__init__()\n","        self.linear = nn.Linear(n_input_features, 1) # Capa lineal, equivalente a hacer f = wx + b\n","\n","    def forward(self, x):\n","        y_pred = torch.sigmoid(self.linear(x)) # Aplica función sigmoide y regresa solución y_pred\n","        return y_pred\n","\n","model = Model(n_features)\n","\n","# 2) Función de pérdida (loss) y optimizador\n","num_epochs = 100\n","learning_rate = 0.01\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","# 3) Ciclo de entrenamiento\n","for epoch in range(num_epochs):\n","    # Forward pass\n","    y_pred = model(X_train) # Observar que no se llama a la función forward.\n","\n","    # Loss\n","    loss = criterion(y_pred, y_train)\n","\n","    # Backward pass\n","    loss.backward()\n","\n","    # Update\n","    optimizer.step()\n","\n","    # Zero grad before new step\n","    optimizer.zero_grad()\n","\n","    if (epoch+1) % 10 == 0:\n","        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n","\n","# 4) Evaluación del modelo\n","with torch.no_grad():\n","    y_predicted = model(X_test)\n","    y_predicted_cls = y_predicted.round()\n","    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n","    print(f'accuracy: {acc.item():.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PD-I644WXhyl"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPJfAMFGY1S5i1zDtpPrl2S","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
